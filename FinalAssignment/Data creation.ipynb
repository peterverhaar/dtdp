{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below can be used to create a data set in CSV format for your research project. It applies most of the methods that have been discussed in the course \"Digital Text and Data Processing\". \n",
    "\n",
    "Requirements:\n",
    "\n",
    "* The texts that you want to mine need to be available in a directory named 'Corpus'. When your files are in a different directory, change the value of the 'dir' variable below.\n",
    "* The files \"Religion.txt\" and \"Politics.txt\" need to be available in the same directory as this notebook. It is possible, of course, to work with other lexicons as well. Lexicon files can be found at https://github.com/peterverhaar/dtdp/tree/master/Texts\n",
    "* A file named \"metadata.csv\" needs to be available in the same directory as this notebook. This CSV file needs to list the names of all the files in your corpus, together with the values for the categorical variables that you want to explore in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "import os\n",
    "from os.path import join\n",
    "import dtdpTdm as dtdp\n",
    "import pandas as pd\n",
    "\n",
    "md = pd.read_csv( 'metadata.csv' )\n",
    "\n",
    "## this dictionary, which links titles to\n",
    "## indices will be used later\n",
    "mdIndices = dict()\n",
    "for index , column in md.iterrows():\n",
    "    mdIndices[ column['title'] ] = index\n",
    "\n",
    "\n",
    "out = open( 'data.csv' , 'w' )\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "## make a header\n",
    "out.write( 'title,tokens,ttr,sentences,syllables,nouns,adjectives,adverbs,fk,religion,politics,century\\n' )\n",
    "\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "\n",
    "        ## extract title from filename by removing extension\n",
    "        title = re.sub( 'b\\.txt' , '' , file )\n",
    "\n",
    "        # full path to file in directory\n",
    "        fileName = join( dir , file )\n",
    "        print(\"Analysing \" + title + \" ...\")\n",
    "        tokens = dtdp.numberOfTokens( fileName )\n",
    "\n",
    "        ## short texts are disregarded\n",
    "        if tokens > 50:\n",
    "            out.write( title + ',' )\n",
    "            print(\"Number of tokens\")\n",
    "            out.write( str( tokens ) )\n",
    "\n",
    "            out.write( ',')\n",
    "\n",
    "            ### type-token ratio\n",
    "            print(\"Calculating type-token ratio\")\n",
    "\n",
    "            textFile = open( fileName )\n",
    "            fullText = textFile.read()\n",
    "\n",
    "            words = dtdp.tokenise( fullText )\n",
    "            if len(words) > 1000:\n",
    "                words = words[0:1000]\n",
    "                tokenCount = 1000\n",
    "            else:\n",
    "                tokenCount = len(words)\n",
    "            freq = dict()\n",
    "\n",
    "            for w in words:\n",
    "                freq[w] = freq.get( w , 0 ) + 1\n",
    "\n",
    "            typeCount = len( freq )\n",
    "\n",
    "            ttr = typeCount / tokenCount\n",
    "\n",
    "            out.write( str( ttr ) )\n",
    "            out.write( ',')\n",
    "\n",
    "            print(\"Number of sentences\")\n",
    "            out.write( str( dtdp.numberOfSentences( fileName ) ) )\n",
    "            out.write( ',')\n",
    "            print(\"Number of syllables\")\n",
    "            out.write( str( dtdp.numberOfSyllables( fileName ) ) )\n",
    "            out.write( ',')\n",
    "            print(\"Number of nouns\")\n",
    "            out.write( str( dtdp.countPosTag( fileName , 'NN')  / tokens ) )\n",
    "            out.write( ',')\n",
    "            print(\"Number of adjectives\")\n",
    "            out.write( str( dtdp.countPosTag( fileName , 'JJ') / tokens  ) )\n",
    "            out.write( ',')\n",
    "            print(\"Number of adverbs\")\n",
    "            out.write( str( dtdp.countPosTag( fileName , 'RB') / tokens  ) )\n",
    "            out.write( ',')\n",
    "            print(\"Flesch-Kincaid\")\n",
    "            out.write( str( dtdp.fleschKincaid( fileName )   ) )\n",
    "            out.write( ',')\n",
    "            print(\"References to religion\")\n",
    "            out.write( str( dtdp.countOccurrencesLexicon( fileName , 'Religion.txt') / tokens  ) )\n",
    "            out.write( ',')\n",
    "            print(\"References to politics\")\n",
    "            out.write( str( dtdp.countOccurrencesLexicon( fileName , 'Politics.txt') / tokens  ) )\n",
    "            out.write( ',')\n",
    "            out.write( str( md.iloc[ mdIndices[file] ]['century' ] ) )\n",
    "            out.write( '\\n')\n",
    "\n",
    "out.close()\n",
    "\n",
    "print(\"\\nThe data set has been created. The name of the file is 'data.csv' \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download the lexicon files that are references in the code above, run the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import time\n",
    "\n",
    "def download( url ):\n",
    "\n",
    "    request = urllib.request.urlopen(url)\n",
    "    bytes = request.read()\n",
    "    fullText = bytes.decode(\"utf-8\")\n",
    "    request.close()\n",
    "\n",
    "    parts = re.split( '/' , url )\n",
    "    id = parts[-1]\n",
    "\n",
    "    out = open( id , 'w' , encoding = 'utf-8')\n",
    "    out.write( fullText )\n",
    "    out.close()\n",
    "\n",
    "\n",
    "\n",
    "urls = [ 'https://raw.githubusercontent.com/peterverhaar/dtdp/master/Texts/Politics.txt' ,\n",
    "'https://raw.githubusercontent.com/peterverhaar/dtdp/master/Texts/Religion.txt' \n",
    "]\n",
    "\n",
    "for item in urls:\n",
    "    print(\"downloading \" + item + \" ...\")\n",
    "    download(item)\n",
    "    \n",
    "print('All files have been downloaded.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
