{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook makes use of the following Python modules:\n",
    "* pandas\n",
    "* seaborn\n",
    "* wordCloud\n",
    "\n",
    "Use the commands in either one of the following cellss to install these packages.\n",
    "For more information, see: https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "\n",
    "If pip has not been installed on your computer, please consult the following resources:\n",
    "\n",
    "https://www.liquidweb.com/kb/install-pip-windows/\n",
    "https://stackoverflow.com/questions/17271319/how-do-i-install-pip-on-macos-or-os-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} pandas\n",
    "!conda install --yes --prefix {sys.prefix} seaborn\n",
    "!conda install --yes --prefix {sys.prefix} wordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install seaborn\n",
    "!{sys.executable} -m pip install wordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "\n",
    "Create a csv file containing data about the text in your corpus. Using the dtdpTdm module, calculate data about the number of tokens, the number of sentences and the number of syllables. You can calculate these data via the following methods:\n",
    "\n",
    "* numberOfTokens\n",
    "* numberOfSentences\n",
    "* numberOfSyllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2\n",
    "\n",
    "Download the following csv file: https://raw.githubusercontent.com/peterverhaar/dtdp/master/Texts/data.csv. Alternatively, use the csv file that you have created yourself for exercise 7.1.\n",
    "\n",
    "Using the pandas library, open the csv and print the following:\n",
    "\n",
    "* information about the number of rows and the number of columns\n",
    "* print the first 3 rows\n",
    "* print a list of all column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.3\n",
    "\n",
    "Using the pandas library, calculate the correlations between the columns in your csv file. Additionally, print a list of the means of all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.4\n",
    "\n",
    "Using the iterrows() method from the pandas library, generate the sentence '&lt;text&gt; contains &lt;x&gt; tokens.' for each row in the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.5\n",
    "\n",
    "Install the module 'seaborn'. Import the module using the following line:\n",
    "\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "```\n",
    "\n",
    "This method can be used to create a heat map. In order to do this, the following code needs to be used:\n",
    "\n",
    "```python\n",
    "ax = sns.heatmap( x , linewidth=0.5 , cmap=\"YlGnBu\" )\n",
    "```\n",
    "\n",
    "Use the seaborn libraries and the pandas libraries to create a heatmap that visualises the correlations between all the columns in the data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv( 'data.csv' )\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "ax = sns.heatmap( df.corr() , linewidth=0.5 , cmap=\"YlGnBu\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.6\n",
    "\n",
    "Use the method tdIdf() from the module dtdtTdm to calculate invesre document frequencies for one of the texts in your corpus. This method requires two parameters: (1) the name of the directory that contains the texts in your corpus and (2) the text whose inversed frequencies you want to see. Visualise the frequencies using a word cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dtdpTdm as dtdp\n",
    "\n",
    "dir = 'Corpus'\n",
    "text = 'VanityFair.txt'\n",
    "\n",
    "freq = dtdp.tdIdf( dir , text )\n",
    "\n",
    "'''\n",
    "sortedList = reversed(sorted( freq , key=lambda x: freq[x]))\n",
    "\n",
    "for w in sortedList:\n",
    "    print( w + ' => ' + str( freq[w] ) )\n",
    "'''\n",
    "    \n",
    "    \n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from wordcloud import WordCloud \n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=1500,height=1000, max_words= 100,relative_scaling=1,normalize_plurals=False).generate_from_frequencies(freq)\n",
    "\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
