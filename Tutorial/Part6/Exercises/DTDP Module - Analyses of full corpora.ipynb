{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Using the code below, try to print a list of the files stored in a folder on yout computer,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        print( join( dir , file ) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "The code below establishes the total number of words and the total number of words of each text in the folder 'Corpus'. Using these two numbers, the average number of words per sentence can also be caclulated. \n",
    "\n",
    "Try to add some code which visualises the average number of words per sentence via a bar chart. You can use the code that was provided as listing 4.1 as a basis: https://github.com/peterverhaar/dtdp/blob/master/Tutorial/Part4/Exercises/exercise4-1.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import dtdpTdm as tdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "titles = []\n",
    "sentenceLength = []\n",
    "\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        \n",
    "        fullPath = join( dir , file )\n",
    "        print( 'Analysing ' +  fullPath + '...' )\n",
    "        tokens = tdm.numberOfTokens( fullPath )\n",
    "        sentences = tdm.numberOfSentences( fullPath )\n",
    "        \n",
    "        sentenceLength.append( tokens / sentences  ) \n",
    "\n",
    "        \n",
    "        title = re.sub( r'\\.txt' , '' , file )\n",
    "        titles.append( title )\n",
    "        \n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "The dtdpTdm module contains a method named countSyllables(). As its own only parameter, the method demands a single English words. The method aims to cacluate the correct number of syllables in the word that is given. Can you find examples of words for which the output is not correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( d.countSyllables(\"beauty\") )\n",
    "print( d.countSyllables(\"believe\") )\n",
    "print( d.countSyllables(\"university\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "Create a scatter plot which visualises both the average length of words (i.e. the average number of syllables per word) and the average length of sentences (i.e. the number of words).\n",
    "\n",
    "For this exercise, you may want to reuse code from exercise 4.4.: https://github.com/peterverhaar/dtdp/blob/master/Tutorial/Part4/Exercises/exercise4-4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import dtdpTdm as tdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "titles = []\n",
    "sentLength = []\n",
    "wordLength = []\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        \n",
    "        title = re.sub( r'\\.txt' , '' , file )\n",
    "        titles.append( title )\n",
    "        print(title)\n",
    "        \n",
    "\n",
    "        \n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "Using the method typeTokenRatioCurve() from the module dtdpTdm, create a line chart which show the type-token curves of all the texts in your corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import dtdpTdm as tdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "colours = [ '#e8e551' , '#403cc1' , '#35872d' , '#cc37c7' , '#e89912' , '#8c1fb7' , '#4cdbbe' , '#6f6b72' , '#bfa2d6' , '#f9b298' , '#efef07' , '#63e24f' , '#f311f7' ]\n",
    "\n",
    "files = []\n",
    "titles = []\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        files.append( join( dir , file ) )\n",
    "        title = re.sub( r'\\.txt' , '' , file )\n",
    "        titles.append( title )\n",
    "        \n",
    "\n",
    "        \n",
    "%matplotlib inline       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "Using the method fleschKincaid() from the module dtdpTdm, create a bar chart which can help you to make a comparative analysis of the levcel of complexity of each of the texts in your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "\n",
    "import dtdpTdm as tdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "titles = []\n",
    "fk = []\n",
    "\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        \n",
    "        fullPath = join( dir , file )\n",
    "        print( 'Analysing ' +  fullPath + '...' )\n",
    "\n",
    "        \n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.11\n",
    "\n",
    "Using the method countOccurrencesLexicon() from the module dtdpTdm, create a scatter plot which visulaised the number of words with a negative connotation and the number of words with a positive connotation. \n",
    "\n",
    "For this exercise, you also need to download the following two files:\n",
    "\n",
    "https://raw.githubusercontent.com/peterverhaar/dtdp/master/Texts/negative.txt\n",
    "\n",
    "https://raw.githubusercontent.com/peterverhaar/dtdp/master/Texts/positive.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import dtdpTdm as tdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "dir = 'Corpus'\n",
    "\n",
    "titles = []\n",
    "positive = []\n",
    "negative = []\n",
    "\n",
    "for file in os.listdir( dir ):\n",
    "    if re.search( r'[.]txt' , file ):\n",
    "        \n",
    "        title = re.sub( r'\\.txt' , '' , file )\n",
    "        titles.append( title )\n",
    "        print(title)\n",
    "        \n",
    "\n",
    "        \n",
    "%matplotlib inline \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
